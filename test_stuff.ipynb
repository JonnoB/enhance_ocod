{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>input:text</th>\n",
       "      <th>input:datapoint_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>street_number</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>207</td>\n",
       "      <td>207 sloane street, london (sw1x 9qx)</td>\n",
       "      <td>53574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>street_name</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>sloane street</td>\n",
       "      <td>207 sloane street, london (sw1x 9qx)</td>\n",
       "      <td>53574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>city</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>london</td>\n",
       "      <td>207 sloane street, london (sw1x 9qx)</td>\n",
       "      <td>53574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>postcode</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "      <td>sw1x 9qx</td>\n",
       "      <td>207 sloane street, london (sw1x 9qx)</td>\n",
       "      <td>53574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unit_type</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>apartment</td>\n",
       "      <td>apartment 533, block 11 spectrum, blackfriars ...</td>\n",
       "      <td>17501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73294</th>\n",
       "      <td>street_number</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>flat a, 49 norcott road, stoke newington, (n16...</td>\n",
       "      <td>76011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73295</th>\n",
       "      <td>street_name</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>norcott road</td>\n",
       "      <td>flat a, 49 norcott road, stoke newington, (n16...</td>\n",
       "      <td>76011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73296</th>\n",
       "      <td>street_number</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>stoke</td>\n",
       "      <td>flat a, 49 norcott road, stoke newington, (n16...</td>\n",
       "      <td>76011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73297</th>\n",
       "      <td>street_number</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>newington</td>\n",
       "      <td>flat a, 49 norcott road, stoke newington, (n16...</td>\n",
       "      <td>76011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73298</th>\n",
       "      <td>postcode</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>n16 7ej</td>\n",
       "      <td>flat a, 49 norcott road, stoke newington, (n16...</td>\n",
       "      <td>76011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73299 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               label  start  end           text  \\\n",
       "0      street_number      0    3            207   \n",
       "1        street_name      4   17  sloane street   \n",
       "2               city     19   25         london   \n",
       "3           postcode     27   35       sw1x 9qx   \n",
       "4          unit_type      0    9      apartment   \n",
       "...              ...    ...  ...            ...   \n",
       "73294  street_number      8   10             49   \n",
       "73295    street_name     11   23   norcott road   \n",
       "73296  street_number     25   30          stoke   \n",
       "73297  street_number     31   40      newington   \n",
       "73298       postcode     43   50        n16 7ej   \n",
       "\n",
       "                                              input:text  input:datapoint_id  \n",
       "0                   207 sloane street, london (sw1x 9qx)               53574  \n",
       "1                   207 sloane street, london (sw1x 9qx)               53574  \n",
       "2                   207 sloane street, london (sw1x 9qx)               53574  \n",
       "3                   207 sloane street, london (sw1x 9qx)               53574  \n",
       "4      apartment 533, block 11 spectrum, blackfriars ...               17501  \n",
       "...                                                  ...                 ...  \n",
       "73294  flat a, 49 norcott road, stoke newington, (n16...               76011  \n",
       "73295  flat a, 49 norcott road, stoke newington, (n16...               76011  \n",
       "73296  flat a, 49 norcott road, stoke newington, (n16...               76011  \n",
       "73297  flat a, 49 norcott road, stoke newington, (n16...               76011  \n",
       "73298  flat a, 49 norcott road, stoke newington, (n16...               76011  \n",
       "\n",
       "[73299 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"enhance_ocod/data/training_data/ground_truth_dev_set_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = pd.read_csv(\"enhance_ocod/data/training_data/parsed_ground_truth_complete.csv\")\n",
    "data = pd.read_csv(\"enhance_ocod/data/training_data/ground_truth_dev_set_labels.csv\").to_dict('records')\n",
    "#data = pd.read_csv(\"enhance_ocod/data/training_data/ground_truth_test_set_labels.csv\").to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "grouped_data = {}\n",
    "for item in data:\n",
    "    datapoint_id = item['input:datapoint_id']\n",
    "    if datapoint_id not in grouped_data:\n",
    "        grouped_data[datapoint_id] = {\n",
    "            \"text\": item['input:text'],\n",
    "            \"entities\": []\n",
    "        }\n",
    "    \n",
    "    grouped_data[datapoint_id][\"entities\"].append({\n",
    "        \"label\": item['label'],\n",
    "        \"start\": item['start'],\n",
    "        \"end\": item['end']\n",
    "    })\n",
    "\n",
    "# Define unique entity labels from your data\n",
    "unique_labels = sorted(set(item['label'] for item in data))\n",
    "\n",
    "# Create BIO tagging scheme\n",
    "bio_labels = [\"O\"]  # Outside any entity\n",
    "for prefix in [\"B\", \"I\"]:  # Beginning and Inside\n",
    "    for label in unique_labels:\n",
    "        bio_labels.append(f\"{prefix}-{label}\")\n",
    "\n",
    "# Create label mappings\n",
    "label2id = {label: i for i, label in enumerate(bio_labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "# Convert to the format needed for token classification\n",
    "processed_examples = []\n",
    "\n",
    "for datapoint in grouped_data.values():\n",
    "    text = datapoint[\"text\"]\n",
    "    entities = datapoint[\"entities\"]\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokenized = tokenizer(text, return_offsets_mapping=True, padding=\"max_length\", truncation=True)\n",
    "    \n",
    "    # Create token tags (using BIO scheme)\n",
    "    tags = [\"O\"] * len(tokenized[\"input_ids\"])\n",
    "    offset_mapping = tokenized.pop(\"offset_mapping\")\n",
    "    \n",
    "    # Map character positions to token positions and assign labels\n",
    "    for entity in entities:\n",
    "        entity_start = entity[\"start\"]\n",
    "        entity_end = entity[\"end\"]\n",
    "        \n",
    "        token_start = None\n",
    "        token_end = None\n",
    "        \n",
    "        for i, (token_start_char, token_end_char) in enumerate(offset_mapping):\n",
    "            # Skip special tokens\n",
    "            if token_start_char == token_end_char == 0:\n",
    "                continue\n",
    "                \n",
    "            if token_start_char <= entity_start < token_end_char:\n",
    "                token_start = i\n",
    "            \n",
    "            if token_start_char < entity_end <= token_end_char:\n",
    "                token_end = i\n",
    "                break\n",
    "        \n",
    "        if token_start is not None and token_end is not None:\n",
    "            # First token gets B- prefix (Beginning)\n",
    "            tags[token_start] = f\"B-{entity['label']}\"\n",
    "            \n",
    "            # Any additional tokens get I- prefix (Inside)\n",
    "            for i in range(token_start + 1, token_end + 1):\n",
    "                tags[i] = f\"I-{entity['label']}\"\n",
    "    \n",
    "    processed_examples.append({\n",
    "        \"input_ids\": tokenized[\"input_ids\"],\n",
    "        \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "        \"labels\": [label2id.get(tag, 0) for tag in tags]  # Convert string labels to IDs\n",
    "    })\n",
    "\n",
    "# Create dataset\n",
    "dataset = Dataset.from_pandas(pd.DataFrame(processed_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing: Flat 3, 25 Test Road, London\n",
      "- UNIT (flat): 'Flat 3'\n",
      "- UNIT (number): '25'\n",
      "- STREET (road_street): 'Road'\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional\n",
    "import re\n",
    "\n",
    "@dataclass\n",
    "class Span:\n",
    "    start: int\n",
    "    end: int\n",
    "    label: str\n",
    "    source: str  # Which pattern matched\n",
    "\n",
    "class AddressParser:\n",
    "    def __init__(self):\n",
    "        self.patterns = self._build_patterns()\n",
    "    \n",
    "    def _build_patterns(self) -> Dict[str, List[re.Pattern]]:\n",
    "        \"\"\"Define and compile regex patterns for each label type.\"\"\"\n",
    "        return {\n",
    "            'BUILDING': [\n",
    "                (re.compile(p, re.IGNORECASE), name) for name, p in [\n",
    "                    ('building_general', r'\\b(house|building|tower)s?\\b'),\n",
    "                    ('company', r'\\b(ltd|limited|plc)\\b'),\n",
    "                ]\n",
    "            ],\n",
    "            'STREET': [\n",
    "                (re.compile(p, re.IGNORECASE), name) for name, p in [\n",
    "                    ('road_street', r'\\b(road|street|lane)\\b'),\n",
    "                    ('avenue', r'\\b(avenue|boulevard)\\b'),\n",
    "                ]\n",
    "            ],\n",
    "            'UNIT': [\n",
    "                (re.compile(p, re.IGNORECASE), name) for name, p in [\n",
    "                    ('flat', r'\\b(flat|apartment)\\s+([A-Z0-9]+)\\b'),\n",
    "                    ('number', r'\\b(no|number)?\\s*(\\d+[A-Z]?)\\b'),\n",
    "                ]\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def find_spans(self, text: str) -> List[Span]:\n",
    "        \"\"\"Find all spans in the text, with conflict resolution.\"\"\"\n",
    "        spans = []\n",
    "        \n",
    "        # Find all matches\n",
    "        for label_type, pattern_list in self.patterns.items():\n",
    "            for pattern, source in pattern_list:\n",
    "                for match in pattern.finditer(text):\n",
    "                    spans.append(Span(\n",
    "                        start=match.start(),\n",
    "                        end=match.end(),\n",
    "                        label=label_type,\n",
    "                        source=source\n",
    "                    ))\n",
    "        \n",
    "        # Simple conflict resolution: keep longest span\n",
    "        spans.sort(key=lambda x: (x.start, -x.end))\n",
    "        filtered = []\n",
    "        last_end = 0\n",
    "        \n",
    "        for span in spans:\n",
    "            if span.start >= last_end:\n",
    "                filtered.append(span)\n",
    "                last_end = span.end\n",
    "        \n",
    "        return filtered\n",
    "\n",
    "\n",
    "parser = AddressParser()\n",
    "text = \"Flat 3, 25 Test Road, London\"\n",
    "\n",
    "print(f\"Parsing: {text}\")\n",
    "for span in parser.find_spans(text):\n",
    "    print(f\"- {span.label} ({span.source}): '{text[span.start:span.end]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Span(start=16, end=20, label='STREET', source='road_street')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
