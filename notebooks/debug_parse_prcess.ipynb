{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from enhance_ocod.address_parsing import (\n",
    "    process_addresses,\n",
    "    expand_dataframe_numbers,\n",
    "    create_unique_id\n",
    ")\n",
    "from enhance_ocod.locate_and_classify import (\n",
    "    load_voa_ratinglist,\n",
    "    add_geographic_metadata,\n",
    "    enhance_ocod_with_gazetteers,\n",
    "    add_business_matches,\n",
    "    property_class,\n",
    "    get_default_property_rules,\n",
    "    fill_unknown_classes_by_group,\n",
    "    drop_non_residential_duplicates\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Downcasting object dtype arrays.*\")\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "SCRIPT_DIR = Path('../notebooks')\n",
    "\n",
    "# ====== PATHS ======\n",
    "def get_first_file_in_data_dir(dirname):\n",
    "    \"\"\"Get the first file in a data subdirectory, or None if no files exist.\"\"\"\n",
    "    data_dir = SCRIPT_DIR.parent / \"data\" / dirname\n",
    "    files = list(data_dir.glob(\"*\"))\n",
    "    return files[0] if files else None\n",
    "\n",
    "ONSPD_path = get_first_file_in_data_dir(\"onspd\")\n",
    "voa_path = get_first_file_in_data_dir(\"voa\")\n",
    "\n",
    "# ====== SPECIFY SINGLE FILE TO DEBUG ======\n",
    "# TODO: Update this path to point to your specific parsed results file\n",
    "parsed_results_file = SCRIPT_DIR.parent / \"data\" / \"parsed_ocod_dicts\" / \"OCOD_FULL_2022_02_parsed_results.pkl\"\n",
    "original_ocod_file = SCRIPT_DIR.parent / \"data\" / \"ocod_history\" / \"OCOD_FULL_2022_02.zip\"\n",
    "output_file = SCRIPT_DIR.parent / \"data\" / \"debug_output.parquet\"\n",
    "\n",
    "print(\"Loading common reference data...\")\n",
    "from enhance_ocod.address_parsing import load_postcode_district_lookup\n",
    "postcode_district_lookup = load_postcode_district_lookup(str(ONSPD_path))\n",
    "voa_businesses = load_voa_ratinglist(str(voa_path), postcode_district_lookup)\n",
    "\n",
    "# Load gazetteers\n",
    "gazetteer_dir = SCRIPT_DIR.parent / 'data'/ 'gazetteer' \n",
    "building_file = gazetteer_dir / 'building_gazetteer.parquet'\n",
    "district_file = gazetteer_dir / 'district_gazetteer.parquet'\n",
    "street_file = gazetteer_dir / 'street_gazetteer.parquet'\n",
    "\n",
    "print(\"Loading gazetteer files...\")\n",
    "building_gazetteer = pd.read_parquet(building_file)\n",
    "district_gazetteer = pd.read_parquet(district_file)\n",
    "street_gazetteer = pd.read_parquet(street_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== LOAD PARSED RESULTS ======\n",
    "print(f\"Loading parsed results from {parsed_results_file}...\")\n",
    "with open(parsed_results_file, \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "print(f\"Loaded results with success rate: {results['summary']['success_rate']:.1%}\")\n",
    "\n",
    "# ====== LOAD ORIGINAL OCOD DATA FOR MERGING ======\n",
    "from enhance_ocod.address_parsing import load_and_prep_OCOD_data\n",
    "print(f\"Loading original OCOD data from {original_ocod_file}...\")\n",
    "ocod_data = load_and_prep_OCOD_data(str(original_ocod_file))\n",
    "\n",
    "# ====== START PROCESSING FROM RESULTS ======\n",
    "print(\"Processing addresses from results...\")\n",
    "processed_addresses_df = process_addresses(results['results'])\n",
    "\n",
    "post_processed_data = processed_addresses_df.merge(\n",
    "    ocod_data, how=\"left\", left_on=\"datapoint_id\", right_index=True\n",
    ")[\n",
    "    [\n",
    "        \"title_number\",\n",
    "        \"tenure\",\n",
    "        \"unit_id\",\n",
    "        \"unit_type\",\n",
    "        \"number_filter\",\n",
    "        \"building_name\",\n",
    "        \"street_number\",\n",
    "        \"street_name\",\n",
    "        \"postcode\",\n",
    "        \"city\",\n",
    "        \"district\",\n",
    "        \"county\",\n",
    "        \"region\",\n",
    "        \"price_paid\",\n",
    "        \"property_address\",\n",
    "        \"country_incorporated\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Clean up memory\n",
    "del ocod_data\n",
    "gc.collect()\n",
    "\n",
    "print(\"Adding geographic metadata...\")\n",
    "post_processed_data[\"postcode\"] = post_processed_data[\"postcode\"].str.upper()\n",
    "pre_process_ocod = add_geographic_metadata(post_processed_data, postcode_district_lookup)\n",
    "\n",
    "print(\"Enhancing with gazetteers...\")\n",
    "pre_process_ocod['building_name'] = pre_process_ocod['building_name'].str.lower()\n",
    "pre_process_ocod['street_name2'] = pre_process_ocod['street_name2'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enhanced = enhance_ocod_with_gazetteers(pre_process_ocod, building_gazetteer, district_gazetteer, street_gazetteer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Adding business matches...\")\n",
    "with_matches = add_business_matches(enhanced, voa_businesses)\n",
    "\n",
    "print(\"Creating temporary unique ID...\")\n",
    "with_matches = create_unique_id(with_matches)\n",
    "\n",
    "print(\"Classifying properties...\")\n",
    "rules = get_default_property_rules()\n",
    "classified = property_class(with_matches.copy(), rules, include_rule_name=True)\n",
    "\n",
    "print(\"Filling unknown classes by group...\")\n",
    "classified = fill_unknown_classes_by_group(classified)\n",
    "\n",
    "print(\"Dropping non-residential duplicates...\")\n",
    "classified = drop_non_residential_duplicates(classified, class_col='class')\n",
    "\n",
    "print(\"Expanding dataframe numbers...\")\n",
    "ocod_data = expand_dataframe_numbers(classified, class_var='class', print_every=10000, min_count=1)\n",
    "\n",
    "print(\"Updating unique ID...\")\n",
    "ocod_data = create_unique_id(ocod_data)\n",
    "\n",
    "# Select final columns\n",
    "columns = [\n",
    "    \"title_number\",\n",
    "    \"multi_id\",\n",
    "    \"unique_id\",\n",
    "    \"unit_id\",\n",
    "    \"unit_type\",\n",
    "    \"building_name\",\n",
    "    \"street_number\",\n",
    "    \"street_name\",\n",
    "    \"postcode\",\n",
    "    \"city\",\n",
    "    \"district\",\n",
    "    \"region\",\n",
    "    \"property_address\",\n",
    "    \"oa11cd\",\n",
    "    \"lsoa11cd\",\n",
    "    \"msoa11cd\",\n",
    "    \"lad11cd\",\n",
    "    \"country_incorporated\",\n",
    "    \"class\",\n",
    "    \"matched_rule\",\n",
    "    \"is_multi\",\n",
    "]\n",
    "\n",
    "ocod_data = ocod_data.loc[:, columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocod_data['lsoa_na'] = ocod_data['lsoa11cd'].isna()\n",
    "\n",
    "\n",
    "ocod_data.groupby('lsoa_na').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(ocod_data['lsoa_na'], ocod_data['class'], margins = True, normalize = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_df = ocod_data.loc[ocod_data['class']=='residential']\n",
    "\n",
    "pd.crosstab(residential_df['lsoa_na'], residential_df['is_multi'], margins = True, normalize = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(ocod_data['matched_rule'], ocod_data['class'], margins = True, normalize = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocod_data.loc[ocod_data['property_address'].str.contains('the white horse', case = False)]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
